\chapter{Results}
\label{chap:res}

\section{Performance Evaluation}
	
	\subsection{Predictive Ability}
	
		Table \ref{tab:performance} shows the predictive ability of the networks. 
		
		Figure \ref{fig:r2} shows a decomposition of $R^2$ into deciles by return.
				
			\begin{table}
				\centering
				\input{Tables/performance.tex}
				\caption{Out-of-Sample Predictive Ability of the Networks}
				\label{tab:performance}
				\medskip
				\small
				NN1 to NN4 stand for neural networks of respective depths. All metrics are calculated out-of-sample and are defined in Section \ref{chap:model_evaluation}.  $R^2$ is in percentage points.  
			\end{table}
		
			\begin{figure}
				\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/r2.pdf}
				\caption{Decomposition of Out-of-Sample $R^2$ into Deciles}
				\label{fig:r2}
				\medskip
				\small 
				NN1 to NN4 stand for neural networks of respective depths. Out-of-sample predictions of each network are split into 10 subsets based on decile of the actual return. $R^2$ of the prediction is then calculated on the individual subsets. For example, decile 10 (100) denotes the bottom (top) 10\% of observations by return (all deciles are mutually exclusive by construction). The figure shows that all networks are able to predict high returns well (decile 80, 90 and 100), but they under-perform the naive prediction of 0 (negative $R^2$) in the low to medium return deciles (30 to 60).  
			\end{figure}
		

	\subsection{Profitability of Trading Strategy (Backtest)}
		\label{chap:backtest}
		
		Figure \ref{fig:backtest_cumreturns_models}, Figure \ref{fig:backtest_histogram}  and Table \ref{tab:backtest_descriptives_models} describe the distribution of monthly returns earned on long-short portfolios generated by the individual networks. The figures also shows the market return, which serves as a benchmark. 
	
		Figure \ref{fig:backtest_cumreturns_ls} shows the decomposition of the cumulative return on the long-short portfolio\footnote{The portfolio is generated by NN1. Other architectures give similar results.} to its long and short legs. The figure also shows the market return, which serves as a benchmark.  
			
		Table \ref{tab:backtest_descriptives_ls} describe the distribution of the monthly returns earned on the long-short portfolio with different capital allocations into the long and short legs.\footnote{The portfolio is generated by NN1. Other architectures give similar results.} 
		
		\afterpage{%    % defer execution until the next page break occurs anyway
			\begin{center}
				\begin{figure}
					\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/backtest_cumreturns_models.pdf}
					\caption{Cumulative Returns on the Long-Short Portfolios}
					\label{fig:backtest_cumreturns_models}
					\medskip
					\small 
				\end{figure}
			\end{center}		
			\begin{table}
				\centering
				\input{Tables/backtest_descriptives_models.tex}
				\caption{Descriptive Statistics of Returns on Long-Short Portfolios}
				\label{tab:backtest_descriptives_models}
			\end{table}
			\begin{center}	
				\begin{figure}
					\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/backtest_histogram.pdf}
					\caption{Histogram of Monthly Returns on the Long-Short Portfolio Generated by NN1}
					\label{fig:backtest_histogram}
				\end{figure}
			\end{center}
			
		} % end of argument of `\afterpage` command
		
		
		\afterpage{%    % defer execution until the next page break occurs anyway
			\begin{center}
				\begin{figure}
					\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Figures/backtest_cumreturns_ls.pdf}
					\caption{Cumulative Returns on Long and Short Legs of the Portfolio Generated by NN1}
					\label{fig:backtest_cumreturns_ls}
				\end{figure}
			\end{center}		
			\begin{table}
				\centering
				\input{Tables/backtest_descriptives_ls.tex}
				\caption{Descriptive Statistics of Returns on Long-Short Portfolios Generated by NN1 in Different Capital Allocations}
				\label{tab:backtest_descriptives_ls}
			\end{table}
			
		} % end of argument of `\afterpage` command
		
		
\section{Global Feature Importance}
	\label{chap:global_feature_importance}
	
	Figures \ref{fig:ig_ensemble} and \ref{fig:pr_ensemble} shows the values of global feature importance for all features, as measured respectively by Global Integrated Gradients and Portfolio Reliance.  
	
	Figure \ref{fig:order} shows how the two measures, Global Integrated Gradients and Portfolio Reliance, order the features by importance. 
	
	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/ig_blues.pdf}
			\caption{Values of Global Integrated Gradient}
			\label{fig:ig_blues}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/ig_relative.pdf}
			\caption{Relative Values of Global Integrated Gradient}
			\label{fig:ig_relative}
		\end{subfigure}
		\caption{Global Feature Importance Measured with Integrated Gradients.}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Panel (\subref{fig:ig_blues}) shows values of the Global Integrated Gradient for all features, for all models.  Panel (\subref{fig:ig_relative}) shows relative importance of the features: values of Global Integrated Gradient are divided by the value for the most important feature, so as to unify the scale across the different models. The features are ordered in descending order by mean value computed across models.
		\label{fig:ig_ensemble}
	\end{figure}
	
	
	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/pr_blues.pdf}
			\caption{Values of Portfolio Reliance}
			\label{fig:pr_blues}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/pr_relative.pdf}
			\caption{Relative Values of Portfolio Reliance}
			\label{fig:pr_relative}
		\end{subfigure}
		\caption{Global Feature Importance Measured with Portfolio Reliance.}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Panel (\subref{fig:pr_blues}) shows values of Portfolio Reliance for all features, for all models.  Panel (\subref{fig:pr_relative}) shows relative importance of the features: values of Portfolio Reliance are divided by the value for the most important feature, so as to unify the scale across the different models. The features are ordered in descending order by mean value computed across models.
		\label{fig:pr_ensemble}
	\end{figure}
	
	
	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/ig_order.pdf}
			\caption{Features Ordered by Global Integrated Gradients}
			\label{fig:ig_order}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/pr_order.pdf}
			\caption{Features Ordered by Portfolio Reliance}
			\label{fig:pr_order}
		\end{subfigure}
		\caption{Order of Features by Their Global Importance}
		\label{fig:order}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Both panels show ordering of features by their global importance, with bright colors corresponding to high order. Label 1 --- bright yellow (30 --- black) corresponds to most (least) important feature in given model, as measured by highest (lowest) Global Integrated Gradient (Panel (\subref{fig:ig_order})) or Portfolio Reliance (Panel (\subref{fig:pr_order})).		
	\end{figure}


\section{Global Feature Importance In Time}

	This section decomposes the main results (presented in Section \ref{chap:global_feature_importance}) into different time periods. Recall from Section \ref{chap:train_regularize_tune} that any model (e.g., NN1) is completely re-trained every year, as new data arrives and the training set thus expands (and validation and testing set rolls forward accordingly). The main results are average across all these independent instances of models in time. This section offers a decomposition. Technically, there are two reasons why feature importance may change in time. Either, the true data-generating process changed (i.e., the relationship between returns and firm characteristics changed), or the model converged to a different solution. TODO the simulations could help distinguish the two, go back to this. 

	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/ig_relative.pdf}
			\caption{Main Result}
			\label{fig:ig_time_main}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/ig_time_relative.pdf}
			\caption{Time Decomposition}
			\label{fig:ig_time_relative}
		\end{subfigure}
		\caption{Global Feature Importance in Time as Measured by Integrated Gradients}
		\label{fig:ig_time}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Both panels show relative values of Global Integrated Gradient: all values are divided by the value for the most important feature, so as to unify the scale across the different models and time periods. 
	\end{figure}

	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/pr_relative.pdf}
			\caption{Main Result}
			\label{fig:pr_time_main}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/pr_time_relative.pdf}
			\caption{Time Decomposition}
			\label{fig:pr_time_relative}
		\end{subfigure}
		\caption{Global Feature Importance in Time as Measured by Portfolio Reliance}
		\label{fig:pr_time}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Both panels show relative values of Portfolio Reliance: all values are divided by the value for the most important feature, so as to unify the scale across the different models and time periods. 
	\end{figure}

\section{Global Feature Importance Across Random Seeds}

	This section decomposes the main results into the component models (random seeds) of the ensemble models presented in Section \ref{chap:global_feature_importance}. Recall from Section \ref{chap:ensembling} that all the models presented in this thesis are ensemble models: each model is an average of 10 different versions of itself, where the versions (called random seed) differ in the initialization of values of the model's weights at the beginning of the training. (Reasons and methodological details of this procedure, called \textit{ensembling}, are discussed in Section \ref{chap:ensembling}.) Decomposing the results into random seeds is useful for several reasons. From one perspective, it can be perceived as a robustness check to see whether small changes in parameter values at the beginning of the optimization influence the results. From the other perspective, it offers a peek into why ensemble models work well: small errors made by the component models average out and the truth arises in the between. As \cite{fisher2019all} write in the title of their paper: "All models are wrong, but many are useful". From this perspectives, if different random seeds find different relationships in the data, the ensemble model can combine this knowledge, which offers it an edge over any of its sub-components. 
	
	Figures \ref{fig:ig_seeds} and \ref{fig:pr_seeds} show how the results of the ensemble models are decomposed into the random seeds. 

	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/ig_relative_without_lr.pdf}
			\caption{Main Result}
			\label{fig:ig_seeds_main}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/ig_seeds_relative.pdf}
			\caption{Decomposition into Random Seeds}
			\label{fig:ig_seeds_relative}
		\end{subfigure}
		\caption{Global Feature Importance across Random Seeds as Measured by Integrated Gradients}
		\label{fig:ig_seeds}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Both panels show relative values of Global Integrated Gradient: all values are divided by the value for the most important feature, so as to unify the scale across the different models. 
	\end{figure}
	
	\begin{figure}	
		\centering		
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{Figures/pr_relative_without_lr.pdf}
			\caption{Main Result}
			\label{fig:pr_seeds_main}
		\end{subfigure}
		
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth]{Figures/pr_seeds_relative.pdf}
			\caption{Decomposition Into Random Seeds}
			\label{fig:pr_seeds_relative}
		\end{subfigure}
		\caption{Global Feature Importance across Random Seeds as Measured by Portfolio Reliance}
		\label{fig:pr_seeds}
		\medskip
		\small
		Column LR shows linear regression and columns NN1 to NN4 the neural networks of respective depths. Both panels show relative values of Portfolio Reliance: all values are divided by the value for the most important feature, so as to unify the scale across the different models.
	\end{figure}
	
	