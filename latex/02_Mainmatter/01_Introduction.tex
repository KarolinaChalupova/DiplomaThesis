\chapter{Introduction}
\label{chap:int}

The question of what explains differences in stock returns between firms has been consuming the academia for over five decades now. The question is interesting from an economist's perspective: putting a price tag on uncertain future payoffs of stocks reflects human impatience and attitudes to risk \citep{cochrane2009asset} and with them, human behavioral biases \citep{kahneman2013prospect}. Stock returns also speak of the complex web of relations between firms: as companies form relationships, they become exposed to similar risks, and their returns correlate \citep{chi2010network}. Thus, studying the cross-section of stock returns is an opportunity to understand human behavior as well as macro-phenomena that emerge in the network of firm's relationships.

The academia has accumulated hundreds of variables that are proposed to explain stock returns. From a statistician's viewpoint, the determinants of stock returns are notoriously over-studied, which brings along the issues of publication bias and multiple hypothesis testing, leading to many false discoveries. \cite{harvey2016and} and \cite{mclean2016does} have famously shown that "most claimed research findings in financial economics are likely false" \cite[p.~5]{harvey2016and} and the field entered a deep crisis. The multidimensional challenge \citep{cochrane2011presidential} emerged: which of the published and unpublished determinants of stock returns are valid, and which are erroneous? What is the wheat, and what is the chaff among stock return predictors?

At the same time, machine learning (ML) drives scientific discovery, progress in many industries and influences human lives day-to-day. Machines don't just play chess and go, drive cars, translate text and recognize images, all better than humans. They are used in basic research in chemistry, and in applied research in medical diagnostics. Machines even do art. [TODO add references to all]. 

Finance is no exception: here as well, ML is gaining popularity both in the academia and the industry. Neural networks in particular beat traditional modeling approaches (such as regression and discriminant analysis) in many financial areas, such as bankruptcy prediction, bank failure prediction, credit rating, bond rating, bond price forecasting, inflation forecasting, and, most often, stock returns prediction \citep{fadlalla2001analysis}. To cite just two more recent examples concerning stock returns: \cite{bryzgalova2019forest} are able to construct discount factor using random trees, overcoming major obstacles with the traditional portfolio-sorts methodology used in finance. \cite{gu2020empirical} and \cite{tobek2020does} show that neural networks used for stock return predictions are 2 to 4 times more profitable in terms of Sharpe ratio than traditional regression approaches.  

However, ML methods, neural networks in particular, are quite complex models and it is therefore challenging to interpret them and explain their decisions. At the same time, interpretability is crucial for many reasons. The first reason is ethical: crudely speaking, we need to know why the auto-driven car did not see the cyclist, why we are not eligible for a loan, and why we are loosing money in the stock market. Sometimes, we even have a \textit{right} to know the explanation to an algorithmic decision, as acknowledged by new European legislation [TODO add citation]. A second reason is practical: it is difficult to improve a model without a deep understanding of how it makes particular decisions. For example, using feature importance measures, one can uncover which inputs to the model are important, and use this knowledge to limit the amount of noise in the model and add stronger predictors \citep{de2018advances}. This brings a need for interpretable, or explainable, ML, now a quickly developing field \citep{molnar2020interpretable}. In other words, as the machine-learning approaches are becoming the norm in the applied field, a need arises to understand the models on a deeper level â€“ which brings us back to the economic underpinnings of stock returns.

It is quite well established that neural networks are the best-performing model to predict stock returns  \citep{gu2020empirical}. However, interpretation of the networks in this domain is yet in its infancy \citep{gu2020empirical}. This thesis aims to fill this gap. It offers three contributions for both academic and applied finance. First, it uncovers which variables the networks consider important for predicting stock returns. Financial constraints, behavioral biases of investors and risk of illiquidity are the groups that appear as most important. This builds on existing findings of \cite{gu2020empirical} and \cite{tobek2020does} while making them more interpretable and precise, by using a measure that is well-grounded in theory and has an interesting and ready interpretation, and by offering detailed decompositions of the results across time, model architectures and ensemble sub-models. Second, this thesis is likely the first work to extract the \textit{sign} of the effect that the predictors have on the predicted returns in neural networks -- it is exciting to see that the direction overwhelmingly agrees with the economic motivations of the predictors. Third, by developing a novel metric of feature importance, Portfolio Reliance, the thesis is in all likelihood the first to point out which variables drive the network's outstanding performance in forming long-short portfolios (predicting the winners and the losers among the stocks). 

Thus, modeling stock returns is viewed from multiple perspectives: the economic one, which strives to understand how investors and firms interact in the supply and demand for information, the statistical one, seeing the gamut of publications and their biases, that of an ML engineer, who sees the problem as making a prediction from noisy data full of complex interactions, and that of a finance practitioner, who strives to identify the future winners and losers in the market. This thesis attempts to bring the four approaches together. I uses use machine learning models to predict stock returns and then interpret them to bring us closer to the answers to the economists' questions. Finally, a finance practitioner can use the now more intelligible model, of which she understands the weaknesses and sources of performance.

The dataset is a liquid universe of globally traded stocks, from 1990 to 2018, and offers 30 stock-level variables that are a distillation of the last 50 years of research in the field. The performance of the networks in this thesis is at par with the state-of-the-art models for stock return prediction, which further enhances its relevance for financial practice. The thesis studies 4 feed-forward neural networks, consisting of 1 to 4 hidden layers. This architecture is ubiquitous in many financial applications \cite{fadlalla2001analysis}, which makes the work quite relevant also to other areas than stock return prediction.    

The thesis is structured as follows: Chaper \ref{chap:lit} offers a review of existing literature, focusing first on the economic motivation of stock return predictors, then on the current state of interpretable ML in stock returns, and finally on the selection of a suitable feature importance measure. Chapter \ref{chap:met} first describes the dataset and then explains the methodology behind training, evaluating and interpreting the networks used. Chapter \ref{chap:res} gives the results, first demonstrating the predictive ability and profitability of the networks, and then diving into their interpretation. Chapter \ref{con} concludes and offers areas for further research. 
